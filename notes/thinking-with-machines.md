<div class="note-meta">December 6, 2025</div>

# On Thinking With Machines

<span class="dropcap">I</span>’ve spent the last week in Paris, reading Sartre in the evenings and tinkering with a few side projects during the day. I didn't intend for the two activities to intersect, but at some point, the combination of distance, philosophy, and practical engineering began informing the same core question: What does it mean to be responsible for the creation of software today?

## When the Hierarchy Breaks

For a long time, the ideal for technology was captured by J.C.R. Licklider’s 1960 vision of Man–Computer Symbiosis.

Licklider envisioned a partnership where the human and machine worked together, but the roles were strictly defined and asymmetrical. The human was the unquestioned expert - the one to set the goals, frame the problems, and judge the correctness. The machine was the tireless executor, handling the tedious, routine, clerical work. The underlying structure of his proposal required the computer to be subordinate to the human's superior knowledge.

In the age of large generative models, that hierarchy has dissolved.

Today, I often find myself in front of a system that possesses knowledge I can’t match - a vast, instant memory of every pattern and architecture. I’m not supervising a subordinate; I’m navigating a dialogue with a system that is often the epistemic engine.

The collaboration feels less like supervision and more like a Socratic seminar:

- The machine offers a confident proposal.
- I question its assumptions and push back on the complexity.
- The machine revises, focusing the solution.
- I narrow the constraints, imposing my taste and context.

The expertise is no longer housed in either of us. It emerges between us, in the back-and-forth of the dialogue. What we have is a system where each side continuously destabilizes and improves the other.

## The Friction of Value

The central difficulty of modern engineering is no longer acquiring technical knowledge. The AI provides that breadth. The true scarcity is the human capacity to define and enforce value.

AI is excellent at optimizing for technical metrics: speed, conciseness, or adherence to a defined pattern. But it is value-neutral. It has no concept of what is good for your team, your business, or your long-term maintainability. It doesn't know the unwritten rules of the world the code must inhabit.

The most profound work the AI forces upon us is engaging with this friction of value:

- The AI can give me a dozen architectural options. I have to choose the one that aligns with my budget, my team’s skill level, and my company’s appetite for risk. I provide the judgment.
- The AI can write code that is technically flawless. I have to ensure the abstraction is readable and aesthetically pleasing to the humans who will maintain it for the next five years. I provide the taste.
- The AI will simply reflect its training data. I have to push back to ensure the system is aligned with ethical standards and legal constraints. I provide the accountability.

## On Thinking with Machines

What should our systems look like if we take this new form of symbiosis seriously?

If the human is no longer the sole expert, and the machine is no longer the mere executor, then developer tools should stop framing themselves around mastery and start framing themselves around dialogue.

The future of engineering will not belong to the top 10 percent of developers in the old sense. It will belong to people who can articulate intent, who can interrogate the machine’s suggestions, who can synthesize competing possibilities into coherent judgment.
